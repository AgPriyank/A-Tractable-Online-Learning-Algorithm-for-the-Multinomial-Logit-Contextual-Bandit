{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Xx8asqjNOfZ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.optimize as opt\n",
        "\n",
        "from scipy.optimize import fmin_tnc\n",
        "from numpy.linalg import inv\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMOhtWyOhlLK"
      },
      "outputs": [],
      "source": [
        "#CB-MNL\n",
        "class cb_mnl2:\n",
        "    def __init__(self, N, K, d, lbd, env_theta):\n",
        "        super(cb_mnl2, self).__init__()\n",
        "        self.N=N\n",
        "        self.K=K\n",
        "        self.d=d\n",
        "        self.env_theta = env_theta\n",
        "        self.X=np.zeros((K,d))[np.newaxis, ...]\n",
        "        self.Y=np.zeros(K+1)[np.newaxis, ...]\n",
        "        self.theta=np.ones(d)/(np.linalg.norm(np.ones(d)))\n",
        "        #self.V=np.zeros((d, d))\n",
        "        self.mnl = RegularizedMNLRegression()\n",
        "        self.lbd = lbd\n",
        "        #self.prev_S = np.zeros(K)\n",
        "        self.S = np.zeros(K)\n",
        "        self.max_assort_theta = np.ones(d)/(np.linalg.norm(np.ones(d)))\n",
        "        \n",
        "    def choose_S(self,t,x):  # x is N*d matrix\n",
        "        # generate theta in lattice\n",
        "        if self.d == 1:\n",
        "          theta_base_set = np.mgrid[-1:1:.2]\n",
        "        elif self.d == 2:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "        elif self.d == 3:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "        elif self.d == 4:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "        elif self.d == 5:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "\n",
        "        total_theta = round((theta_base_set.size)/self.d)\n",
        "        ran = round((total_theta)**(1/self.d))\n",
        "\n",
        "        beta_sq = .0001*self.d*np.log(self.K*t)\n",
        "        max_assort_val= 0\n",
        "        max_assort_single = []\n",
        "        max_assort_theta =[]\n",
        "        counter_theta = counter_unitball=0\n",
        "        for i in range(0,ran):\n",
        "          for j in range(0,ran):\n",
        "            for k in range(0,ran):\n",
        "              theta_val = theta_base_set[:,i,j,k]\n",
        "              if np.linalg.norm(theta_val) <= 1:\n",
        "                counter_unitball = counter_unitball+1\n",
        "                if self.in_confidence_set(theta_val,beta_sq)==1:\n",
        "                  counter_theta = counter_theta +1\n",
        "                  means = np.dot(x,theta_val)\n",
        "                  assort_single = np.argsort(means)[::-1][:self.K]\n",
        "                  assort_means = np.dot(x[assort_single,:],theta_val)\n",
        "                  assort_val = self.assort_value(assort_means)\n",
        "                  if assort_val > max_assort_val:\n",
        "                    max_assort_single = assort_single\n",
        "                    max_assort_val = assort_val\n",
        "                    self.max_assort_theta = theta_val\n",
        "        \n",
        "        if len(max_assort_single) ==0:\n",
        "          means = np.dot(x,theta_val)\n",
        "          assort_single = np.argsort(means)[::-1][:self.K]\n",
        "          self.S = assort_single\n",
        "          print(\"time\", t) \n",
        "        else:\n",
        "          self.S =max_assort_single\n",
        "        self.X = np.concatenate((self.X, x[self.S,:][np.newaxis, ...]))\n",
        "\n",
        "        return(self.S)\n",
        "        \n",
        "\n",
        "    def update_theta(self,Y,t):\n",
        "        self.Y = np.concatenate((self.Y, Y[np.newaxis, ...]))\n",
        "        if t==2:\n",
        "            self.X = np.delete(self.X, (0), axis=0)\n",
        "            self.Y = np.delete(self.Y, (0), axis=0)\n",
        "        self.lbd = 2*d*np.log(self.K*t)\n",
        "        self.mnl.fit(self.X, self.Y, self.theta, self.lbd)\n",
        "        self.theta = self.mnl.w\n",
        "    \n",
        "    \n",
        "    def in_confidence_set(self,theta_val,beta_sq):\n",
        "        \n",
        "        log_loss_theta_val = self.cost_function(theta_val,self.X,self.Y,lbd)\n",
        "        log_loss_theta_est = self.cost_function(self.theta,self.X,self.Y,lbd)\n",
        "        if  log_loss_theta_est < beta_sq + log_loss_theta_val:\n",
        "          return 1\n",
        "        else:\n",
        "          return 0\n",
        "\n",
        "    def compute_prob(self, theta, x):\n",
        "        means = np.dot(x, theta)\n",
        "        u = np.exp(means)\n",
        "        u_ones = np.column_stack((u,np.ones(u.shape[0])))\n",
        "        logSumExp = u_ones.sum(axis=1)\n",
        "        prob = u_ones/logSumExp[:,None]\n",
        "        return prob\n",
        "\n",
        "    def cost_function(self, theta, x, y, lam):\n",
        "        m = x.shape[0]\n",
        "        prob = self.compute_prob(theta, x)\n",
        "        return np.sum( np.multiply(y, np.log(prob))) - .5*lam*np.linalg.norm(theta)\n",
        "\n",
        "    def assort_value(self,means):\n",
        "        u = np.exp(means)\n",
        "        uSum = 1 + u.sum()\n",
        "        rwd = u.sum()/uSum\n",
        "        return rwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iz5q2LwWouo"
      },
      "outputs": [],
      "source": [
        "#CB-MNL\n",
        "class cb_mnl_d5:\n",
        "    def __init__(self, N, K, d, lbd, env_theta):\n",
        "        super(cb_mnl_d5, self).__init__()\n",
        "        self.N=N\n",
        "        self.K=K\n",
        "        self.d=d\n",
        "        self.env_theta = env_theta\n",
        "        self.X=np.zeros((K,d))[np.newaxis, ...]\n",
        "        self.Y=np.zeros(K+1)[np.newaxis, ...]\n",
        "        self.theta=np.ones(d)/(np.linalg.norm(np.ones(d)))\n",
        "        self.mnl = RegularizedMNLRegression()\n",
        "        self.lbd = lbd\n",
        "        self.S = np.zeros(K)\n",
        "        self.max_assort_theta = np.ones(d)/(np.linalg.norm(np.ones(d)))\n",
        "\n",
        "    \n",
        "        \n",
        "    def choose_S(self,t,x):  # x is N*d matrix\n",
        "        # generate theta in lattice\n",
        "        if self.d == 1:\n",
        "          theta_base_set = np.mgrid[-1:1:.2]\n",
        "        elif self.d == 2:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "        elif self.d == 3:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "        elif self.d == 4:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "        elif self.d == 5:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "\n",
        "        total_theta = round((theta_base_set.size)/self.d)\n",
        "        ran = round((total_theta)**(1/self.d))\n",
        "\n",
        "        beta_sq = .0001*self.d*np.log(self.K*t)\n",
        "        max_assort_val= 0\n",
        "        max_assort_single = []\n",
        "        max_assort_theta =[]\n",
        "        counter_theta = counter_unitball=0\n",
        "        for i in range(0,ran):\n",
        "          for j in range(0,ran):\n",
        "            for k in range(0,ran):\n",
        "              for l in range(0,ran):\n",
        "                for m in range(0,ran):\n",
        "                  theta_val = theta_base_set[:,i,j,k,l,m]\n",
        "                  if np.linalg.norm(theta_val) <= 1:\n",
        "                    counter_unitball = counter_unitball+1\n",
        "                    ### test in confidence set\n",
        "                    if self.in_confidence_set(theta_val,beta_sq)==1:\n",
        "                      counter_theta = counter_theta +1\n",
        "                      means = np.dot(x,theta_val)\n",
        "                      assort_single = np.argsort(means)[::-1][:self.K]\n",
        "                      assort_means = np.dot(x[assort_single,:],theta_val)\n",
        "                      assort_val = self.assort_value(assort_means)\n",
        "                      if assort_val > max_assort_val:\n",
        "                        max_assort_single = assort_single\n",
        "                        max_assort_val = assort_val\n",
        "                        self.max_assort_theta = theta_val\n",
        "        \n",
        "        if len(max_assort_single) ==0:\n",
        "          means = np.dot(x,theta_val)\n",
        "          assort_single = np.argsort(means)[::-1][:self.K]\n",
        "          self.S = assort_single\n",
        "        else:\n",
        "          self.S =max_assort_single\n",
        "        self.X = np.concatenate((self.X, x[self.S,:][np.newaxis, ...]))\n",
        "\n",
        "        return(self.S)\n",
        "        \n",
        "\n",
        "    def update_theta(self,Y,t):\n",
        "        self.Y = np.concatenate((self.Y, Y[np.newaxis, ...]))\n",
        "        if t==2:\n",
        "            self.X = np.delete(self.X, (0), axis=0)\n",
        "            self.Y = np.delete(self.Y, (0), axis=0)\n",
        "        self.lbd = 2*d*np.log(self.K*t)\n",
        "        self.mnl.fit(self.X, self.Y, self.theta, self.lbd)\n",
        "        self.theta = self.mnl.w\n",
        "    \n",
        "    \n",
        "    def in_confidence_set(self,theta_val,beta_sq):\n",
        "        \n",
        "        log_loss_theta_val = self.cost_function(theta_val,self.X,self.Y,lbd)\n",
        "        log_loss_theta_est = self.cost_function(self.theta,self.X,self.Y,lbd)\n",
        "        if  log_loss_theta_est < beta_sq + log_loss_theta_val:\n",
        "          return 1\n",
        "        else:\n",
        "          return 0\n",
        "\n",
        "    def compute_prob(self, theta, x):\n",
        "        means = np.dot(x, theta)\n",
        "        u = np.exp(means)\n",
        "        u_ones = np.column_stack((u,np.ones(u.shape[0])))\n",
        "        logSumExp = u_ones.sum(axis=1)\n",
        "        prob = u_ones/logSumExp[:,None]\n",
        "        return prob\n",
        "\n",
        "    def cost_function(self, theta, x, y, lam):\n",
        "        m = x.shape[0]\n",
        "        prob = self.compute_prob(theta, x)\n",
        "        return np.sum( np.multiply(y, np.log(prob))) - .5*lam*np.linalg.norm(theta)\n",
        "\n",
        "    def assort_value(self,means):\n",
        "        u = np.exp(means)\n",
        "        uSum = 1 + u.sum()\n",
        "        rwd = u.sum()/uSum\n",
        "        return rwd\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}