{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Xx8asqjNOfZ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.optimize as opt\n",
        "\n",
        "from itertools import combinations\n",
        "np.random.seed(7)\n",
        "from scipy.optimize import fmin_tnc\n",
        "from numpy.linalg import inv\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNeQo_B-poD6"
      },
      "outputs": [],
      "source": [
        "## From Oh & Iyengar (non-public code)\n",
        "class mnlEnv:\n",
        "    def __init__(self, theta, K):\n",
        "        super(mnlEnv, self).__init__()\n",
        "        self.theta = theta\n",
        "        self.K = K\n",
        "        \n",
        "    def compute_rwd(self, means):\n",
        "        u = np.exp(means)\n",
        "        uSum = 1 + u.sum()\n",
        "        prob = np.append(u, [1])/uSum\n",
        "        rwd = u.sum()/uSum\n",
        "        Y = np.random.multinomial(1, prob)\n",
        "        return rwd, Y\n",
        "    \n",
        "    def get_opt_rwd(self, x):\n",
        "        opt_means = np.sort(np.dot(x,self.theta))[::-1][:self.K]\n",
        "        rwd, Y = self.compute_rwd(opt_means)\n",
        "        return rwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SE2t-4ypzv7"
      },
      "outputs": [],
      "source": [
        "## From Oh & Iyengar (non-public code)\n",
        "class RegularizedMNLRegression:\n",
        "\n",
        "    def compute_prob(self, theta, x):\n",
        "        means = np.dot(x, theta)\n",
        "        u = np.exp(means)\n",
        "        u_ones = np.column_stack((u,np.ones(u.shape[0])))\n",
        "        logSumExp = u_ones.sum(axis=1)\n",
        "        prob = u_ones/logSumExp[:,None]\n",
        "        return prob\n",
        "\n",
        "    def cost_function(self, theta, x, y, lam):\n",
        "        m = x.shape[0]\n",
        "        prob = self.compute_prob(theta, x)\n",
        "        return -(1/m)*np.sum( np.multiply(y, np.log(prob))) + (1/m)*lam*np.linalg.norm(theta)\n",
        "\n",
        "    def gradient(self, theta, x, y, lam):\n",
        "        m = x.shape[0]\n",
        "        prob = self.compute_prob(theta, x)\n",
        "        eps = (prob-y)[:,:-1]\n",
        "        grad = (1/m)*np.tensordot(eps,x,axes=([1,0],[1,0])) + (1/m)*lam*theta\n",
        "        return grad\n",
        "\n",
        "    def fit(self, x, y, theta, lam):\n",
        "        opt_weights = fmin_tnc(func=self.cost_function, x0=theta, fprime=self.gradient, args=(x, y, lam))\n",
        "        self.w = opt_weights[0]\n",
        "        return self"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLFOluT0Nm7F"
      },
      "outputs": [],
      "source": [
        "## From Oh & Iyengar (non-public code)\n",
        "class MNLRegression:\n",
        "\n",
        "    def compute_prob(self, theta, x, y):\n",
        "        means = np.dot(x, theta)\n",
        "        u = np.exp(means)\n",
        "        u_ones = np.column_stack((u,np.ones(u.shape[0])))\n",
        "        logSumExp = u_ones.sum(axis=1)\n",
        "        prob = u_ones/logSumExp[:,None]\n",
        "        return prob\n",
        "\n",
        "    def cost_function(self, theta, x, y):\n",
        "        m = x.shape[0]\n",
        "        prob = self.compute_prob(theta, x, y)\n",
        "        return -(1/m)*np.sum( np.multiply(y, np.log(prob)))\n",
        "\n",
        "    def gradient(self, theta, x, y):\n",
        "        m = x.shape[0]\n",
        "        prob = self.compute_prob(theta, x, y)\n",
        "        eps = (prob-y)[:,:-1]\n",
        "        grad = (1/m)*np.tensordot(eps,x,axes=([1,0],[1,0]))\n",
        "        return grad\n",
        "\n",
        "    def fit(self, x, y, theta):\n",
        "        opt_weights = fmin_tnc(func=self.cost_function, x0=theta, fprime=self.gradient, args=(x, y))\n",
        "        self.w = opt_weights[0]\n",
        "        return self"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HSMFyYDVI9A"
      },
      "outputs": [],
      "source": [
        "## From Oh & Iyengar (non-public code)\n",
        "class ts_mnl:\n",
        "    def __init__(self, N, K, d, T0, kappa = 0.5, alpha=None):\n",
        "        super(ts_mnl, self).__init__()\n",
        "        self.N=N\n",
        "        self.K=K\n",
        "        self.d=d\n",
        "        self.X=np.zeros((K,d))[np.newaxis, ...]\n",
        "        self.Y=np.zeros(K+1)[np.newaxis, ...]\n",
        "        self.T0=T0\n",
        "        self.kappa=kappa\n",
        "        self.theta=np.zeros(d)\n",
        "        self.V=np.zeros((d, d))\n",
        "        self.mnl=MNLRegression()\n",
        "        self.alpha=alpha\n",
        "        \n",
        "    def choose_S(self,t,x):  # x is N*d matrix\n",
        "        if t < self.T0:\n",
        "            self.S = np.random.choice(self.N,self.K, replace=False)\n",
        "        else:\n",
        "            if self.alpha is None:\n",
        "                self.alpha = (1/(2*self.kappa))*np.sqrt(2*self.d*np.log(1+t/self.d)+2*np.log(t))\n",
        "            theta_tilde = np.random.multivariate_normal(self.theta, np.square(self.alpha)*inv(self.V))\n",
        "            means = np.dot(x,theta_tilde)            \n",
        "            self.S = np.argsort(means)[::-1][:self.K]\n",
        "        self.X = np.concatenate((self.X, x[self.S,:][np.newaxis, ...]))\n",
        "        self.V += np.matmul(x[self.S,:].T, x[self.S,:])\n",
        "        return(self.S)\n",
        "\n",
        "    def update_theta(self,Y,t):\n",
        "        self.Y = np.concatenate((self.Y, Y[np.newaxis, ...]))\n",
        "        if t==2:\n",
        "            self.X = np.delete(self.X, (0), axis=0)\n",
        "            self.Y = np.delete(self.Y, (0), axis=0)\n",
        "        if t>self.T0:\n",
        "            self.mnl.fit(self.X, self.Y, self.theta)\n",
        "            self.theta = self.mnl.w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mu-XQXz0VHeG"
      },
      "outputs": [],
      "source": [
        "## From Oh & Iyengar (non-public code)\n",
        "#UCB-MNL\n",
        "class ucb_mnl:\n",
        "    def __init__(self, N, K, d, T0, kappa = 10000, alpha=None):\n",
        "        super(ucb_mnl, self).__init__()\n",
        "        self.N=N\n",
        "        self.K=K\n",
        "        self.d=d\n",
        "        self.X=np.zeros((K,d))[np.newaxis, ...]\n",
        "        self.Y=np.zeros(K+1)[np.newaxis, ...]\n",
        "        self.T0=T0\n",
        "        self.kappa=kappa\n",
        "        self.theta=np.zeros(d)\n",
        "        self.V=np.zeros((d, d))\n",
        "        self.mnl = MNLRegression()\n",
        "        self.alpha=alpha\n",
        "        self.prev_S = np.zeros(K)\n",
        "        \n",
        "    def choose_S(self,t,x):  # x is N*d matrix\n",
        "        if t < self.T0:\n",
        "            self.S = np.random.choice(self.N,self.K, replace=False)\n",
        "        else:\n",
        "            if self.alpha is None:\n",
        "                self.alpha = (1/(2*self.kappa))*np.sqrt(2*self.d*np.log(1+t/self.d)+2*np.log(t))\n",
        "            means = np.dot(x,self.theta)\n",
        "            xv = np.sqrt((np.matmul(x, inv(self.V)) * x).sum(axis = 1))\n",
        "            u = means + self.alpha * xv\n",
        "            self.S = np.argsort(u)[::-1][:self.K]\n",
        "        self.X = np.concatenate((self.X, x[self.S,:][np.newaxis, ...]))\n",
        "        self.V += np.matmul(x[self.S,:].T, x[self.S,:])\n",
        "        return(self.S)\n",
        "\n",
        "    def update_theta(self,Y,t):\n",
        "        self.Y = np.concatenate((self.Y, Y[np.newaxis, ...]))\n",
        "        if t==2:\n",
        "            self.X = np.delete(self.X, (0), axis=0)\n",
        "            self.Y = np.delete(self.Y, (0), axis=0)\n",
        "        if t>self.T0:\n",
        "            self.mnl.fit(self.X, self.Y, self.theta)\n",
        "            self.theta = self.mnl.w\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMOhtWyOhlLK"
      },
      "outputs": [],
      "source": [
        "#CB-MNL\n",
        "class cb_mnl2:\n",
        "    def __init__(self, N, K, d, lbd, env_theta):\n",
        "        super(cb_mnl2, self).__init__()\n",
        "        self.N=N\n",
        "        self.K=K\n",
        "        self.d=d\n",
        "        self.env_theta = env_theta\n",
        "        self.X=np.zeros((K,d))[np.newaxis, ...]\n",
        "        self.Y=np.zeros(K+1)[np.newaxis, ...]\n",
        "        self.theta=np.ones(d)/(np.linalg.norm(np.ones(d)))\n",
        "        #self.V=np.zeros((d, d))\n",
        "        self.mnl = RegularizedMNLRegression()\n",
        "        self.lbd = lbd\n",
        "        #self.prev_S = np.zeros(K)\n",
        "        self.S = np.zeros(K)\n",
        "        self.max_assort_theta = np.ones(d)/(np.linalg.norm(np.ones(d)))\n",
        "        \n",
        "    def choose_S(self,t,x):  # x is N*d matrix\n",
        "        # generate theta in lattice\n",
        "        if self.d == 1:\n",
        "          theta_base_set = np.mgrid[-1:1:.2]\n",
        "        elif self.d == 2:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "        elif self.d == 3:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "        elif self.d == 4:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "        elif self.d == 5:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "\n",
        "        total_theta = round((theta_base_set.size)/self.d)\n",
        "        ran = round((total_theta)**(1/self.d))\n",
        "\n",
        "        beta_sq = .0001*self.d*np.log(self.K*t)\n",
        "        max_assort_val= 0\n",
        "        max_assort_single = []\n",
        "        max_assort_theta =[]\n",
        "        counter_theta = counter_unitball=0\n",
        "        for i in range(0,ran):\n",
        "          for j in range(0,ran):\n",
        "            for k in range(0,ran):\n",
        "              theta_val = theta_base_set[:,i,j,k]\n",
        "              if np.linalg.norm(theta_val) <= 1:\n",
        "                counter_unitball = counter_unitball+1\n",
        "                if self.in_confidence_set(theta_val,beta_sq)==1:\n",
        "                  counter_theta = counter_theta +1\n",
        "                  means = np.dot(x,theta_val)\n",
        "                  assort_single = np.argsort(means)[::-1][:self.K]\n",
        "                  assort_means = np.dot(x[assort_single,:],theta_val)\n",
        "                  assort_val = self.assort_value(assort_means)\n",
        "                  if assort_val > max_assort_val:\n",
        "                    max_assort_single = assort_single\n",
        "                    max_assort_val = assort_val\n",
        "                    self.max_assort_theta = theta_val\n",
        "        \n",
        "        if len(max_assort_single) ==0:\n",
        "          means = np.dot(x,theta_val)\n",
        "          assort_single = np.argsort(means)[::-1][:self.K]\n",
        "          self.S = assort_single\n",
        "          print(\"time\", t) \n",
        "        else:\n",
        "          self.S =max_assort_single\n",
        "        self.X = np.concatenate((self.X, x[self.S,:][np.newaxis, ...]))\n",
        "\n",
        "        return(self.S)\n",
        "        \n",
        "\n",
        "    def update_theta(self,Y,t):\n",
        "        self.Y = np.concatenate((self.Y, Y[np.newaxis, ...]))\n",
        "        if t==2:\n",
        "            self.X = np.delete(self.X, (0), axis=0)\n",
        "            self.Y = np.delete(self.Y, (0), axis=0)\n",
        "        self.lbd = 2*d*np.log(self.K*t)\n",
        "        self.mnl.fit(self.X, self.Y, self.theta, self.lbd)\n",
        "        self.theta = self.mnl.w\n",
        "    \n",
        "    \n",
        "    def in_confidence_set(self,theta_val,beta_sq):\n",
        "        \n",
        "        log_loss_theta_val = self.cost_function(theta_val,self.X,self.Y,lbd)\n",
        "        log_loss_theta_est = self.cost_function(self.theta,self.X,self.Y,lbd)\n",
        "        if  log_loss_theta_est < beta_sq + log_loss_theta_val:\n",
        "          return 1\n",
        "        else:\n",
        "          return 0\n",
        "\n",
        "    def compute_prob(self, theta, x):\n",
        "        means = np.dot(x, theta)\n",
        "        u = np.exp(means)\n",
        "        u_ones = np.column_stack((u,np.ones(u.shape[0])))\n",
        "        logSumExp = u_ones.sum(axis=1)\n",
        "        prob = u_ones/logSumExp[:,None]\n",
        "        return prob\n",
        "\n",
        "    def cost_function(self, theta, x, y, lam):\n",
        "        m = x.shape[0]\n",
        "        prob = self.compute_prob(theta, x)\n",
        "        return np.sum( np.multiply(y, np.log(prob))) - .5*lam*np.linalg.norm(theta)\n",
        "\n",
        "    def assort_value(self,means):\n",
        "        u = np.exp(means)\n",
        "        uSum = 1 + u.sum()\n",
        "        rwd = u.sum()/uSum\n",
        "        return rwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iz5q2LwWouo"
      },
      "outputs": [],
      "source": [
        "#CB-MNL\n",
        "class cb_mnl_d5:\n",
        "    def __init__(self, N, K, d, lbd, env_theta):\n",
        "        super(cb_mnl_d5, self).__init__()\n",
        "        self.N=N\n",
        "        self.K=K\n",
        "        self.d=d\n",
        "        self.env_theta = env_theta\n",
        "        self.X=np.zeros((K,d))[np.newaxis, ...]\n",
        "        self.Y=np.zeros(K+1)[np.newaxis, ...]\n",
        "        self.theta=np.ones(d)/(np.linalg.norm(np.ones(d)))\n",
        "        self.mnl = RegularizedMNLRegression()\n",
        "        self.lbd = lbd\n",
        "        self.S = np.zeros(K)\n",
        "        self.max_assort_theta = np.ones(d)/(np.linalg.norm(np.ones(d)))\n",
        "\n",
        "    \n",
        "        \n",
        "    def choose_S(self,t,x):  # x is N*d matrix\n",
        "        # generate theta in lattice\n",
        "        if self.d == 1:\n",
        "          theta_base_set = np.mgrid[-1:1:.2]\n",
        "        elif self.d == 2:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "        elif self.d == 3:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "        elif self.d == 4:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "        elif self.d == 5:\n",
        "          theta_base_set = np.mgrid[-1:1:.2,-1:1:.2,-1:1:.2,-1:1:.2,-1:1:.2]\n",
        "\n",
        "        total_theta = round((theta_base_set.size)/self.d)\n",
        "        ran = round((total_theta)**(1/self.d))\n",
        "\n",
        "        beta_sq = .0001*self.d*np.log(self.K*t)\n",
        "        max_assort_val= 0\n",
        "        max_assort_single = []\n",
        "        max_assort_theta =[]\n",
        "        counter_theta = counter_unitball=0\n",
        "        for i in range(0,ran):\n",
        "          for j in range(0,ran):\n",
        "            for k in range(0,ran):\n",
        "              for l in range(0,ran):\n",
        "                for m in range(0,ran):\n",
        "                  theta_val = theta_base_set[:,i,j,k,l,m]\n",
        "                  if np.linalg.norm(theta_val) <= 1:\n",
        "                    counter_unitball = counter_unitball+1\n",
        "                    ### test in confidence set\n",
        "                    if self.in_confidence_set(theta_val,beta_sq)==1:\n",
        "                      counter_theta = counter_theta +1\n",
        "                      means = np.dot(x,theta_val)\n",
        "                      assort_single = np.argsort(means)[::-1][:self.K]\n",
        "                      assort_means = np.dot(x[assort_single,:],theta_val)\n",
        "                      assort_val = self.assort_value(assort_means)\n",
        "                      if assort_val > max_assort_val:\n",
        "                        max_assort_single = assort_single\n",
        "                        max_assort_val = assort_val\n",
        "                        self.max_assort_theta = theta_val\n",
        "        \n",
        "        if len(max_assort_single) ==0:\n",
        "          means = np.dot(x,theta_val)\n",
        "          assort_single = np.argsort(means)[::-1][:self.K]\n",
        "          self.S = assort_single\n",
        "        else:\n",
        "          self.S =max_assort_single\n",
        "        self.X = np.concatenate((self.X, x[self.S,:][np.newaxis, ...]))\n",
        "\n",
        "        return(self.S)\n",
        "        \n",
        "\n",
        "    def update_theta(self,Y,t):\n",
        "        self.Y = np.concatenate((self.Y, Y[np.newaxis, ...]))\n",
        "        if t==2:\n",
        "            self.X = np.delete(self.X, (0), axis=0)\n",
        "            self.Y = np.delete(self.Y, (0), axis=0)\n",
        "        self.lbd = 2*d*np.log(self.K*t)\n",
        "        self.mnl.fit(self.X, self.Y, self.theta, self.lbd)\n",
        "        self.theta = self.mnl.w\n",
        "    \n",
        "    \n",
        "    def in_confidence_set(self,theta_val,beta_sq):\n",
        "        \n",
        "        log_loss_theta_val = self.cost_function(theta_val,self.X,self.Y,lbd)\n",
        "        log_loss_theta_est = self.cost_function(self.theta,self.X,self.Y,lbd)\n",
        "        if  log_loss_theta_est < beta_sq + log_loss_theta_val:\n",
        "          return 1\n",
        "        else:\n",
        "          return 0\n",
        "\n",
        "    def compute_prob(self, theta, x):\n",
        "        means = np.dot(x, theta)\n",
        "        u = np.exp(means)\n",
        "        u_ones = np.column_stack((u,np.ones(u.shape[0])))\n",
        "        logSumExp = u_ones.sum(axis=1)\n",
        "        prob = u_ones/logSumExp[:,None]\n",
        "        return prob\n",
        "\n",
        "    def cost_function(self, theta, x, y, lam):\n",
        "        m = x.shape[0]\n",
        "        prob = self.compute_prob(theta, x)\n",
        "        return np.sum( np.multiply(y, np.log(prob))) - .5*lam*np.linalg.norm(theta)\n",
        "\n",
        "    def assort_value(self,means):\n",
        "        u = np.exp(means)\n",
        "        uSum = 1 + u.sum()\n",
        "        rwd = u.sum()/uSum\n",
        "        return rwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzqC96xYNcvQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sample_spherical(N, k):\n",
        "    vec = np.random.randn(k, N)\n",
        "    vec /= np.linalg.norm(vec, axis=0)\n",
        "    return vec\n",
        "\n",
        "def sample_elliptical(N, d, k, mu):\n",
        "    S = sample_spherical(N, k)\n",
        "    A = np.random.rand(d,k)\n",
        "    R = np.random.normal(size=N)\n",
        "    return mu + A.dot(R*S)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "N = 15\n",
        "K = 4\n",
        "d = 5\n",
        "T = 100\n",
        "dist = 0\n",
        "\n",
        "MC_counts = 25\n",
        "cumulated_regret_cb_mnl2 = np.zeros((MC_counts,T))\n",
        "cumulated_regret_ucb_mnl = np.zeros((MC_counts,T))\n",
        "cumulated_regret_ts_mnl = np.zeros((MC_counts,T))\n",
        "cumulated_regret_ucb_mnl_klow = np.zeros((MC_counts,T))\n",
        "cumulated_regret_ts_mnl_klow = np.zeros((MC_counts,T))\n",
        "cumulated_regret_ucb_mnl_kinter = np.zeros((MC_counts,T))\n",
        "cumulated_regret_ts_mnl_kinter = np.zeros((MC_counts,T))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "T0 = 5*np.sqrt(d)\n",
        "for mc in range(MC_counts):\n",
        "  cumulated_regret_single_cb_mnl2 =[]\n",
        "  cumulated_regret_single_ucb_mnl =[]\n",
        "  cumulated_regret_single_ts_mnl =[]\n",
        "  cumulated_regret_single_ucb_mnl_klow =[]\n",
        "  cumulated_regret_single_ts_mnl_klow =[]\n",
        "  cumulated_regret_single_ucb_mnl_kinter =[]\n",
        "  cumulated_regret_single_ts_mnl_kinter =[]\n",
        "  sigma_sq=1\n",
        "  rho_sq= 0\n",
        "  W=(sigma_sq-rho_sq)*np.eye(N) + rho_sq*np.ones((N,N))\n",
        "  dist=0\n",
        "  theta=np.random.uniform(0.,1.,d)\n",
        "  env=mnlEnv(theta, K)\n",
        "  env_theta= theta\n",
        "  lbd=.001*d*np.log(K*T)\n",
        "  M1=cb_mnl_d5(N=N, K=K, d=d, lbd=lbd, env_theta=env_theta)\n",
        "  M2=ucb_mnl(N=N, K=K, d=d, T0=T0, kappa = .001)\n",
        "  M3=ts_mnl(N=N, K=K, d=d, T0=T0, kappa = .001)\n",
        "  M4=ucb_mnl(N=N, K=K, d=d, T0=T0, kappa = .1)\n",
        "  M5=ts_mnl(N=N, K=K, d=d, T0=T0, kappa = .1)\n",
        "  M6=ucb_mnl(N=N, K=K, d=d, T0=T0, kappa = .01)\n",
        "  M7=ts_mnl(N=N, K=K, d=d, T0=T0, kappa = .01)\n",
        "  RWD1=list()\n",
        "  optRWD=list()\n",
        "  RWD2=list()\n",
        "  optRWD2=list()\n",
        "  RWD3=list()\n",
        "  optRWD3=list()\n",
        "  RWD4=list()\n",
        "  optRWD4=list()\n",
        "  RWD5=list()\n",
        "  optRWD5=list()\n",
        "  RWD6=list()\n",
        "  optRWD6=list()\n",
        "  RWD7=list()\n",
        "  optRWD7=list()\n",
        "  for t in range(T):\n",
        "    lbd=.001*d*np.log(K*T)\n",
        "    if dist == 0:\n",
        "      x=np.random.multivariate_normal(np.zeros(N),W,d).T\n",
        "    elif dist == 1:\n",
        "      x=(np.random.random((N, d)) * 2 - 1)\n",
        "    elif dist == 2:\n",
        "      x=sample_elliptical(N, d, int(d/2), 0).T\n",
        "\t\n",
        "    S1=M1.choose_S(t+1,x)\n",
        "    rwd1, Y1 = env.compute_rwd(np.dot(x[S1,:],theta))\n",
        "    RWD1.append(rwd1)\n",
        "    M1.update_theta(Y1,t+1)\n",
        "    opt_rwd = env.get_opt_rwd(x)\n",
        "    optRWD.append(opt_rwd)\n",
        "    cumulated_regret_single_cb_mnl2.append(np.cumsum(optRWD)-np.cumsum(RWD1))\n",
        "    \n",
        "    S2=M2.choose_S(t+1,x)\n",
        "    rwd2, Y2 = env.compute_rwd(np.dot(x[S2,:],theta))\n",
        "    RWD2.append(rwd2)\n",
        "    M2.update_theta(Y2,t+1)\n",
        "    opt_rwd2 = env.get_opt_rwd(x)\n",
        "    optRWD2.append(opt_rwd2)\n",
        "    cumulated_regret_single_ucb_mnl.append(np.cumsum(optRWD2)-np.cumsum(RWD2))\n",
        "\n",
        "    S3=M3.choose_S(t+1,x)\n",
        "    rwd3, Y3 = env.compute_rwd(np.dot(x[S3,:],theta))\n",
        "    RWD3.append(rwd3)\n",
        "    M3.update_theta(Y3,t+1)\n",
        "    opt_rwd3 = env.get_opt_rwd(x)\n",
        "    optRWD3.append(opt_rwd3)\n",
        "    cumulated_regret_single_ts_mnl.append(np.cumsum(optRWD3)-np.cumsum(RWD3))\n",
        "  \n",
        "    S4=M4.choose_S(t+1,x)\n",
        "    rwd4, Y4 = env.compute_rwd(np.dot(x[S4,:],theta))\n",
        "    RWD4.append(rwd4)\n",
        "    M4.update_theta(Y4,t+1)\n",
        "    opt_rwd4 = env.get_opt_rwd(x)\n",
        "    optRWD4.append(opt_rwd4)\n",
        "    cumulated_regret_single_ucb_mnl_klow.append(np.cumsum(optRWD4)-np.cumsum(RWD4))\n",
        "  \n",
        "    S5=M5.choose_S(t+1,x)\n",
        "    rwd5, Y5 = env.compute_rwd(np.dot(x[S5,:],theta))\n",
        "    RWD5.append(rwd5)\n",
        "    M5.update_theta(Y5,t+1)\n",
        "    opt_rwd5 = env.get_opt_rwd(x)\n",
        "    optRWD5.append(opt_rwd5)\n",
        "    cumulated_regret_single_ts_mnl_klow.append(np.cumsum(optRWD5)-np.cumsum(RWD5))\n",
        "\n",
        "\n",
        "    S6=M6.choose_S(t+1,x)\n",
        "    rwd6, Y6 = env.compute_rwd(np.dot(x[S6,:],theta))\n",
        "    RWD6.append(rwd6)\n",
        "    M6.update_theta(Y6,t+1)\n",
        "    opt_rwd6 = env.get_opt_rwd(x)\n",
        "    optRWD6.append(opt_rwd6)\n",
        "    cumulated_regret_single_ucb_mnl_kinter.append(np.cumsum(optRWD6)-np.cumsum(RWD6))\n",
        "  \n",
        "    S7=M7.choose_S(t+1,x)\n",
        "    rwd7, Y7 = env.compute_rwd(np.dot(x[S7,:],theta))\n",
        "    RWD7.append(rwd7)\n",
        "    M7.update_theta(Y7,t+1)\n",
        "    opt_rwd7 = env.get_opt_rwd(x)\n",
        "    optRWD7.append(opt_rwd7)\n",
        "    cumulated_regret_single_ts_mnl_kinter.append(np.cumsum(optRWD5)-np.cumsum(RWD5))\n",
        "  cumulated_regret_cb_mnl2[mc,:] = cumulated_regret_single_cb_mnl2[T-1]\n",
        "  cumulated_regret_ucb_mnl[mc,:] = cumulated_regret_single_ucb_mnl[T-1]\n",
        "  cumulated_regret_ts_mnl[mc,:] = cumulated_regret_single_ts_mnl[T-1]\n",
        "  \n",
        "\n",
        "  cumulated_regret_ucb_mnl_klow[mc,:] = cumulated_regret_single_ucb_mnl_klow[T-1]\n",
        "  cumulated_regret_ts_mnl_klow[mc,:] = cumulated_regret_single_ts_mnl_klow[T-1]\n",
        "  cumulated_regret_ucb_mnl_kinter[mc,:] = cumulated_regret_single_ucb_mnl_kinter[T-1]\n",
        "  cumulated_regret_ts_mnl_kinter[mc,:] = cumulated_regret_single_ts_mnl_kinter[T-1]  \n",
        "  \n",
        "\n",
        "\n",
        "plottable_cumulated_regret_cb_mnl2 = np.mean(cumulated_regret_cb_mnl2,axis=0)\n",
        "plottable_cumulated_regret_ucb_mnl = np.mean(cumulated_regret_ucb_mnl,axis=0)\n",
        "plottable_cumulated_regret_ts_mnl = np.mean(cumulated_regret_ts_mnl,axis=0)\n",
        "\n",
        "plottable_cumulated_regret_ucb_mnl_klow = np.mean(cumulated_regret_ucb_mnl_klow,axis=0)\n",
        "plottable_cumulated_regret_ts_mnl_klow = np.mean(cumulated_regret_ts_mnl_klow,axis=0)\n",
        "\n",
        "plottable_cumulated_regret_ucb_mnl_kinter = np.mean(cumulated_regret_ucb_mnl_kinter,axis=0)\n",
        "plottable_cumulated_regret_ts_mnl_kinter = np.mean(cumulated_regret_ts_mnl_kinter,axis=0)\n",
        "\n",
        "\n",
        "plottable_cumulated_regret_cb_mnl2_std = np.std(cumulated_regret_cb_mnl2,axis=0)\n",
        "plottable_cumulated_regret_ucb_mnl_std = np.std(cumulated_regret_ucb_mnl,axis=0)\n",
        "plottable_cumulated_regret_ts_mnl_std = np.std(cumulated_regret_ts_mnl,axis=0)\n",
        "\n",
        "plottable_cumulated_regret_ucb_mnl_klow_std = np.std(cumulated_regret_ucb_mnl_klow,axis=0)\n",
        "plottable_cumulated_regret_ts_mnl_klow_std = np.std(cumulated_regret_ts_mnl_klow,axis=0)\n",
        "\n",
        "plottable_cumulated_regret_ucb_mnl_kinter_std = np.std(cumulated_regret_ucb_mnl_kinter,axis=0)\n",
        "plottable_cumulated_regret_ts_mnl_kinter_std = np.std(cumulated_regret_ts_mnl_kinter,axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P_1Jmktmzo6"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickling_on = open(\"algo_comp_N_15_K_4_d_5_T_100_mc_25\",\"wb\")\n",
        "pickle.dump(cumulated_regret_cb_mnl2, pickling_on) \n",
        "pickle.dump(cumulated_regret_ucb_mnl, pickling_on)\n",
        "pickle.dump(cumulated_regret_ts_mnl, pickling_on)\n",
        "pickle.dump(cumulated_regret_ucb_mnl_klow, pickling_on)\n",
        "pickle.dump(cumulated_regret_ts_mnl_klow, pickling_on)\n",
        "pickle.dump(cumulated_regret_ucb_mnl_kinter, pickling_on)\n",
        "pickle.dump(cumulated_regret_ts_mnl_kinter, pickling_on)\n",
        "pickling_on.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldFqz10BZzkr"
      },
      "outputs": [],
      "source": [
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "N = 10\n",
        "K = 6\n",
        "d = 3\n",
        "T = 100\n",
        "dist = 0\n",
        "#T0 = 5*np.sqrt(d)\n",
        "\n",
        "sigma_sq=1.\n",
        "rho_sq= 0\n",
        "W=(sigma_sq-rho_sq)*np.eye(N) + rho_sq*np.ones((N,N))\n",
        "MC_counts = 25\n",
        "cumulated_regret_cb_mnl2 = np.zeros((MC_counts,T))\n",
        "cumulated_regret_single_cb_mnl2 =[]\n",
        "cumulated_regret_ucb_mnl = np.zeros((MC_counts,T))\n",
        "cumulated_regret_single_ucb_mnl =[]\n",
        "cumulated_regret_ts_mnl = np.zeros((MC_counts,T))\n",
        "cumulated_regret_single_ts_mnl =[]\n",
        "cumulated_regret_ucb_mnl_klow = np.zeros((MC_counts,T))\n",
        "cumulated_regret_single_ucb_mnl_klow =[]\n",
        "cumulated_regret_ts_mnl_klow = np.zeros((MC_counts,T))\n",
        "cumulated_regret_single_ts_mnl_klow =[]\n",
        "\n",
        "T0 = 5*np.sqrt(d)\n",
        "for mc in range(MC_counts):\n",
        "  cumulated_regret_single_cb_mnl2 =[]\n",
        "  cumulated_regret_single_ucb_mnl =[]\n",
        "  cumulated_regret_single_ts_mnl =[]\n",
        "  cumulated_regret_single_ucb_mnl_klow =[]\n",
        "  cumulated_regret_single_ts_mnl_klow =[]\n",
        "  theta=np.random.uniform(0.,1.,d)\n",
        "  env=mnlEnv(theta, K)\n",
        "  env_theta= theta\n",
        "  lbd=.01*d*np.log(K*T)\n",
        "  M1=cb_mnl2(N=N, K=K, d=d, lbd=lbd, env_theta=env_theta)\n",
        "  M2=ucb_mnl(N=N, K=K, d=d, T0=T0, kappa = .001)\n",
        "  M3=ts_mnl(N=N, K=K, d=d, T0=T0, kappa = .001)\n",
        "  M4=ucb_mnl(N=N, K=K, d=d, T0=T0, kappa = 1)\n",
        "  M5=ts_mnl(N=N, K=K, d=d, T0=T0, kappa = 1)\n",
        "  RWD1=list()\n",
        "  optRWD=list()\n",
        "  RWD2=list()\n",
        "  optRWD2=list()\n",
        "  RWD3=list()\n",
        "  optRWD3=list()\n",
        "  RWD4=list()\n",
        "  optRWD4=list()\n",
        "  RWD5=list()\n",
        "  optRWD5=list()\n",
        "  for t in range(T):\n",
        "    lbd=.01*d*np.log(K*T)\n",
        "    if dist == 0:\n",
        "      x=np.random.multivariate_normal(np.zeros(N),W,d).T\n",
        "    elif dist == 1:\n",
        "      x=(np.random.random((N, d)) * 2 - 1)\n",
        "    elif dist == 2:\n",
        "      x=sample_elliptical(N, d, int(d/2), 0).T\n",
        "\t\n",
        "    S1=M1.choose_S(t+1,x)\n",
        "    rwd1, Y1 = env.compute_rwd(np.dot(x[S1,:],theta))\n",
        "    RWD1.append(rwd1)\n",
        "    M1.update_theta(Y1,t+1)\n",
        "    opt_rwd = env.get_opt_rwd(x)\n",
        "    optRWD.append(opt_rwd)\n",
        "    cumulated_regret_single_cb_mnl2.append(np.cumsum(optRWD)-np.cumsum(RWD1))\n",
        "    \n",
        "    S2=M2.choose_S(t+1,x)\n",
        "    rwd2, Y2 = env.compute_rwd(np.dot(x[S2,:],theta))\n",
        "    RWD2.append(rwd2)\n",
        "    M2.update_theta(Y2,t+1)\n",
        "    opt_rwd2 = env.get_opt_rwd(x)\n",
        "    optRWD2.append(opt_rwd2)\n",
        "    cumulated_regret_single_ucb_mnl.append(np.cumsum(optRWD2)-np.cumsum(RWD2))\n",
        "\n",
        "    S3=M3.choose_S(t+1,x)\n",
        "    rwd3, Y3 = env.compute_rwd(np.dot(x[S3,:],theta))\n",
        "    RWD3.append(rwd3)\n",
        "    M3.update_theta(Y3,t+1)\n",
        "    opt_rwd3 = env.get_opt_rwd(x)\n",
        "    optRWD3.append(opt_rwd3)\n",
        "    cumulated_regret_single_ts_mnl.append(np.cumsum(optRWD3)-np.cumsum(RWD3))\n",
        "  \n",
        "    S4=M4.choose_S(t+1,x)\n",
        "    rwd4, Y4 = env.compute_rwd(np.dot(x[S4,:],theta))\n",
        "    RWD4.append(rwd4)\n",
        "    M4.update_theta(Y4,t+1)\n",
        "    opt_rwd4 = env.get_opt_rwd(x)\n",
        "    optRWD4.append(opt_rwd4)\n",
        "    cumulated_regret_single_ucb_mnl_klow.append(np.cumsum(optRWD4)-np.cumsum(RWD4))\n",
        "  \n",
        "    S5=M5.choose_S(t+1,x)\n",
        "    rwd5, Y5 = env.compute_rwd(np.dot(x[S5,:],theta))\n",
        "    RWD5.append(rwd5)\n",
        "    M5.update_theta(Y5,t+1)\n",
        "    opt_rwd5 = env.get_opt_rwd(x)\n",
        "    optRWD5.append(opt_rwd5)\n",
        "    cumulated_regret_single_ts_mnl_klow.append(np.cumsum(optRWD5)-np.cumsum(RWD5))\n",
        "  \n",
        "\n",
        "  cumulated_regret_cb_mnl2[mc,:] = cumulated_regret_single_cb_mnl2[T-1]\n",
        "  cumulated_regret_ucb_mnl[mc,:] = cumulated_regret_single_ucb_mnl[T-1]\n",
        "  cumulated_regret_ts_mnl[mc,:] = cumulated_regret_single_ts_mnl[T-1]\n",
        "  cumulated_regret_ucb_mnl_klow[mc,:] = cumulated_regret_single_ucb_mnl_klow[T-1]\n",
        "  cumulated_regret_ts_mnl_klow[mc,:] = cumulated_regret_single_ts_mnl_klow[T-1]  \n",
        "\n",
        "\n",
        "plottable_cumulated_regret_cb_mnl2 = np.mean(cumulated_regret_cb_mnl2,axis=0)\n",
        "plottable_cumulated_regret_ucb_mnl = np.mean(cumulated_regret_ucb_mnl,axis=0)\n",
        "plottable_cumulated_regret_ts_mnl = np.mean(cumulated_regret_ts_mnl,axis=0)\n",
        "\n",
        "plottable_cumulated_regret_ucb_mnl_klow = np.mean(cumulated_regret_ucb_mnl_klow,axis=0)\n",
        "plottable_cumulated_regret_ts_mnl_klow = np.mean(cumulated_regret_ts_mnl_klow,axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82Iuwl47mzpN"
      },
      "outputs": [],
      "source": [
        "pickling_on = open(\"algo_comp_N_10_K_6_d_3_T_100_mc_25\",\"wb\")\n",
        "pickle.dump(cumulated_regret_cb_mnl2, pickling_on) \n",
        "pickle.dump(cumulated_regret_ucb_mnl, pickling_on)\n",
        "pickle.dump(cumulated_regret_ts_mnl, pickling_on)\n",
        "pickle.dump(cumulated_regret_ucb_mnl_klow, pickling_on)\n",
        "pickle.dump(cumulated_regret_ts_mnl_klow, pickling_on)\n",
        "pickling_on.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fr6moIXsoidN"
      },
      "outputs": [],
      "source": [
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "N = 20\n",
        "K = 5\n",
        "d = 3\n",
        "T = 100\n",
        "dist = 0\n",
        "\n",
        "sigma_sq=1.\n",
        "rho_sq= 0\n",
        "W=(sigma_sq-rho_sq)*np.eye(N) + rho_sq*np.ones((N,N))\n",
        "\n",
        "MC_counts = 25\n",
        "cumulated_regret_cb_mnl2 = np.zeros((MC_counts,T))\n",
        "\n",
        "cumulated_regret_single_cb_mnl2 =[]\n",
        "\n",
        "\n",
        "\n",
        "cumulated_regret_ucb_mnl = np.zeros((MC_counts,T))\n",
        "\n",
        "cumulated_regret_single_ucb_mnl =[]\n",
        "\n",
        "\n",
        "\n",
        "cumulated_regret_ts_mnl = np.zeros((MC_counts,T))\n",
        "\n",
        "cumulated_regret_single_ts_mnl =[]\n",
        "\n",
        "\n",
        "\n",
        "cumulated_regret_ucb_mnl_klow = np.zeros((MC_counts,T))\n",
        "\n",
        "cumulated_regret_single_ucb_mnl_klow =[]\n",
        "\n",
        "\n",
        "\n",
        "cumulated_regret_ts_mnl_klow = np.zeros((MC_counts,T))\n",
        "\n",
        "cumulated_regret_single_ts_mnl_klow =[]\n",
        "\n",
        "\n",
        "\n",
        "T0 = 5*np.sqrt(d)\n",
        "for mc in range(MC_counts):\n",
        "  cumulated_regret_single_cb_mnl2 =[]\n",
        "  cumulated_regret_single_ucb_mnl =[]\n",
        "  cumulated_regret_single_ts_mnl =[]\n",
        "  cumulated_regret_single_ucb_mnl_klow =[]\n",
        "  cumulated_regret_single_ts_mnl_klow =[]\n",
        "  theta=np.random.uniform(0.,1.,d)\n",
        "  env=mnlEnv(theta, K)\n",
        "  env_theta= theta\n",
        "  lbd=.01*d*np.log(K*T)\n",
        "  M1=cb_mnl2(N=N, K=K, d=d, lbd=lbd, env_theta=env_theta)\n",
        "  M2=ucb_mnl(N=N, K=K, d=d, T0=T0, kappa = .001)\n",
        "  M3=ts_mnl(N=N, K=K, d=d, T0=T0, kappa = .001)\n",
        "  M4=ucb_mnl(N=N, K=K, d=d, T0=T0, kappa = 1)\n",
        "  M5=ts_mnl(N=N, K=K, d=d, T0=T0, kappa = 1)\n",
        "  RWD1=list()\n",
        "  optRWD=list()\n",
        "  RWD2=list()\n",
        "  optRWD2=list()\n",
        "  RWD3=list()\n",
        "  optRWD3=list()\n",
        "\n",
        "  RWD4=list()\n",
        "  optRWD4=list()\n",
        "  RWD5=list()\n",
        "  optRWD5=list()\n",
        "  for t in range(T):\n",
        "    lbd=.01*d*np.log(K*T)\n",
        "    if dist == 0:\n",
        "      x=np.random.multivariate_normal(np.zeros(N),W,d).T\n",
        "    elif dist == 1:\n",
        "      x=(np.random.random((N, d)) * 2 - 1)\n",
        "    elif dist == 2:\n",
        "      x=sample_elliptical(N, d, int(d/2), 0).T\n",
        "\t\n",
        "    S1=M1.choose_S(t+1,x)\n",
        "    rwd1, Y1 = env.compute_rwd(np.dot(x[S1,:],theta))\n",
        "    RWD1.append(rwd1)\n",
        "    M1.update_theta(Y1,t+1)\n",
        "    opt_rwd = env.get_opt_rwd(x)\n",
        "    optRWD.append(opt_rwd)\n",
        "    cumulated_regret_single_cb_mnl2.append(np.cumsum(optRWD)-np.cumsum(RWD1))\n",
        "    \n",
        "    S2=M2.choose_S(t+1,x)\n",
        "    rwd2, Y2 = env.compute_rwd(np.dot(x[S2,:],theta))\n",
        "    RWD2.append(rwd2)\n",
        "    M2.update_theta(Y2,t+1)\n",
        "    opt_rwd2 = env.get_opt_rwd(x)\n",
        "    optRWD2.append(opt_rwd2)\n",
        "    cumulated_regret_single_ucb_mnl.append(np.cumsum(optRWD2)-np.cumsum(RWD2))\n",
        "\n",
        "    S3=M3.choose_S(t+1,x)\n",
        "    rwd3, Y3 = env.compute_rwd(np.dot(x[S3,:],theta))\n",
        "    RWD3.append(rwd3)\n",
        "    M3.update_theta(Y3,t+1)\n",
        "    opt_rwd3 = env.get_opt_rwd(x)\n",
        "    optRWD3.append(opt_rwd3)\n",
        "    cumulated_regret_single_ts_mnl.append(np.cumsum(optRWD3)-np.cumsum(RWD3))\n",
        "  \n",
        "    S4=M4.choose_S(t+1,x)\n",
        "    rwd4, Y4 = env.compute_rwd(np.dot(x[S4,:],theta))\n",
        "    RWD4.append(rwd4)\n",
        "    M4.update_theta(Y4,t+1)\n",
        "    opt_rwd4 = env.get_opt_rwd(x)\n",
        "    optRWD4.append(opt_rwd4)\n",
        "    cumulated_regret_single_ucb_mnl_klow.append(np.cumsum(optRWD4)-np.cumsum(RWD4))\n",
        "  \n",
        "    S5=M5.choose_S(t+1,x)\n",
        "    rwd5, Y5 = env.compute_rwd(np.dot(x[S5,:],theta))\n",
        "    RWD5.append(rwd5)\n",
        "    M5.update_theta(Y5,t+1)\n",
        "    opt_rwd5 = env.get_opt_rwd(x)\n",
        "    optRWD5.append(opt_rwd5)\n",
        "    cumulated_regret_single_ts_mnl_klow.append(np.cumsum(optRWD5)-np.cumsum(RWD5))\n",
        "  \n",
        "\n",
        "  cumulated_regret_cb_mnl2[mc,:] = cumulated_regret_single_cb_mnl2[T-1]\n",
        "  cumulated_regret_ucb_mnl[mc,:] = cumulated_regret_single_ucb_mnl[T-1]\n",
        "  cumulated_regret_ts_mnl[mc,:] = cumulated_regret_single_ts_mnl[T-1]\n",
        "  cumulated_regret_ucb_mnl_klow[mc,:] = cumulated_regret_single_ucb_mnl_klow[T-1]\n",
        "  cumulated_regret_ts_mnl_klow[mc,:] = cumulated_regret_single_ts_mnl_klow[T-1]  \n",
        "\n",
        "\n",
        "plottable_cumulated_regret_cb_mnl2 = np.mean(cumulated_regret_cb_mnl2,axis=0)\n",
        "plottable_cumulated_regret_ucb_mnl = np.mean(cumulated_regret_ucb_mnl,axis=0)\n",
        "plottable_cumulated_regret_ts_mnl = np.mean(cumulated_regret_ts_mnl,axis=0)\n",
        "\n",
        "plottable_cumulated_regret_ucb_mnl_klow = np.mean(cumulated_regret_ucb_mnl_klow,axis=0)\n",
        "plottable_cumulated_regret_ts_mnl_klow = np.mean(cumulated_regret_ts_mnl_klow,axis=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn9RP2ftmzpa"
      },
      "outputs": [],
      "source": [
        "pickling_on = open(\"algo_comp_N_20_K_5_d_3_T_100_mc_25\",\"wb\")\n",
        "pickle.dump(cumulated_regret_cb_mnl2, pickling_on) \n",
        "pickle.dump(cumulated_regret_ucb_mnl, pickling_on)\n",
        "pickle.dump(cumulated_regret_ts_mnl, pickling_on)\n",
        "pickle.dump(cumulated_regret_ucb_mnl_klow, pickling_on)\n",
        "pickle.dump(cumulated_regret_ts_mnl_klow, pickling_on)\n",
        "pickling_on.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}